{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 후보/연도별로 연설 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for file in glob.glob('./data/to_preprocess/*'):\n",
    "    df_curr = pd.read_csv(file, index_col=0)\n",
    "    df_curr[\"Year\"] = int(file.split(\"\\\\\")[-1][0:4])\n",
    "    if df is None:\n",
    "        df = df_curr\n",
    "    else:\n",
    "        df = pd.concat([df,df_curr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연도 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df.groupby(\"Year\")[\"Year\"].value_counts().plot.bar(ax=ax)\n",
    "# ax.hist(df[\"Year\"], bins=range(1920,2024,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 후보별 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "df.groupby(\"name\")[\"name\"].value_counts().plot.bar(ax=ax)\n",
    "# ax.hist(df[\"name\"])\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"joined_speech\"] = df[\"speech\"].apply(lambda l: ' '.join(ast.literal_eval(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(df[\"joined_speech\"].apply(lambda l: len(l.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ast.literal_eval(df[\"speech\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install wordcloud -y\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('./data/orig/2020_Trump_speech.csv', index_col=0)\n",
    "\n",
    "speeches = list(map(lambda l: ' '.join(ast.literal_eval(l)), df_test[\"speech\"].values))\n",
    "\n",
    "\n",
    "\n",
    "speeches_processed = list()\n",
    "for word in speeches:\n",
    "    if word not in stop_words_list:\n",
    "        speeches_processed.append(word)\n",
    "\n",
    "speeches_combined = ' '.join(speeches_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color = 'black',\n",
    "    width = 1000, height = 500).generate(speeches_combined)\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/to_preprocess/2020_Biden_speech_edited.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = list(map(lambda l: ' '.join(ast.literal_eval(l)), df_test[\"speech\"].values))\n",
    "\n",
    "speeches_combined = ' '.join(speeches)\n",
    "\n",
    "speeches_processed = list()\n",
    "for word in speeches:\n",
    "    if word not in stop_words_list:\n",
    "        speeches_processed.append(word)\n",
    "\n",
    "speeches_combined = ' '.join(speeches_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color = 'black',\n",
    "    width = 1000, height = 500).generate(speeches_combined)\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda x: re.sub('[,\\.!?]','',x)\n",
    "\n",
    "lambda x: x.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim_utils import simple_preprocess\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install nltk -y\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download(\"punkt\")\n",
    "stop_words_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech_whole\"] = df[\"speech\"].apply(lambda l: ' '.join(ast.literal_eval(l)))\n",
    "# ast.literal_eval(df[\"speech\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(token_list):\n",
    "    filtered_list = list()\n",
    "    for token in token_list:\n",
    "        if token not in stop_words_list:\n",
    "            filtered_list.append(token)\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nonwords(string):\n",
    "    out = string\n",
    "    out = re.sub('[-–—–;]', ' ', out)\n",
    "    out = re.sub('[,\\.!?\"\\'`]','', out)\n",
    "    out = re.sub('[^a-zA-Z0-9\\-_./]','', out)\n",
    "    out = out.lower()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech_processed\"] = df[\"speech_whole\"].apply(filter_nonwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech_processed\"] = df[\"speech_processed\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech_processed\"] = df[\"speech_processed\"].apply(filter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1][\"speech_processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install gensim -y\n",
    "\n",
    "dictionary = corpora.Dictionary(df[\"speech_processed\"])\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in df[\"speech_processed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(dictionary.values())\n",
    "words.sort(key=lambda x:len(x), reverse=True)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 15\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=n_topics, id2word=dictionary, passes=15, random_state=42)\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=n_topics, id2word=dictionary, passes=15, random_state=42)\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_model.print_topics(num_words=10)\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic_list in enumerate(lda_model[corpus]):\n",
    "    print(i,'번째 문서의 topic 비율은',topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
